#!/bin/bash
# RANOnline LLM Integration - One-Click Demo Launch Script
# ä¸€éµæ¼”ç¤ºå•Ÿå‹•è…³æœ¬ï¼Œå¿«é€Ÿå±•ç¤ºç³»çµ±åŠŸèƒ½

set -e

# é¡è‰²å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

echo -e "${CYAN}================================================${NC}"
echo -e "${CYAN}ðŸš€ RANOnline LLM Integration - Demo Launcher${NC}"
echo -e "${CYAN}================================================${NC}"

# æª¢æŸ¥ Ollama æœå‹™
echo -e "${YELLOW}ðŸ” Checking Ollama service...${NC}"
if ! curl -s --connect-timeout 3 http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo -e "${YELLOW}âš ï¸  Ollama service not running. Starting Ollama...${NC}"
    
    # å˜—è©¦å•Ÿå‹• Ollama æœå‹™
    if command -v ollama &> /dev/null; then
        ollama serve &
        OLLAMA_PID=$!
        echo -e "${BLUE}ðŸ“‹ Ollama PID: ${OLLAMA_PID}${NC}"
        
        # ç­‰å¾…æœå‹™å•Ÿå‹•
        echo -e "${YELLOW}â³ Waiting for Ollama to start...${NC}"
        for i in {1..30}; do
            if curl -s --connect-timeout 1 http://localhost:11434/api/tags > /dev/null 2>&1; then
                echo -e "${GREEN}âœ… Ollama service started successfully${NC}"
                break
            fi
            sleep 1
        done
    else
        echo -e "${RED}âŒ Ollama not found. Please install Ollama first.${NC}"
        exit 1
    fi
else
    echo -e "${GREEN}âœ… Ollama service is running${NC}"
fi

# æª¢æŸ¥å¿…è¦æ¨¡åž‹
echo -e "${YELLOW}ðŸ¤– Checking available models...${NC}"
MODELS=$(curl -s http://localhost:11434/api/tags | jq -r '.models[].name' 2>/dev/null || echo "")

if [ -z "$MODELS" ]; then
    echo -e "${YELLOW}âš ï¸  No models found. Downloading demo models...${NC}"
    
    # ä¸‹è¼‰å°åž‹æ¼”ç¤ºæ¨¡åž‹
    echo -e "${BLUE}ðŸ“¥ Downloading phi3:mini (2.3GB)...${NC}"
    ollama pull phi3:mini
    
    echo -e "${BLUE}ðŸ“¥ Downloading gemma:2b (1.4GB)...${NC}"
    ollama pull gemma:2b
    
    echo -e "${GREEN}âœ… Demo models downloaded${NC}"
else
    echo -e "${GREEN}âœ… Available models:${NC}"
    echo "$MODELS" | while read -r model; do
        if [ -n "$model" ]; then
            echo -e "${BLUE}   - ${model}${NC}"
        fi
    done
fi

# æª¢æŸ¥æ‡‰ç”¨ç¨‹å¼
APP_PATH="./build/RANOnline_LLM_Integration"
if [ ! -f "$APP_PATH" ]; then
    echo -e "${YELLOW}ðŸ”¨ Application not found. Building...${NC}"
    
    # å¿«é€Ÿå»ºç½®
    mkdir -p build
    cd build
    cmake .. -DCMAKE_BUILD_TYPE=Release -DBUILD_LLM_TESTS=OFF
    cmake --build . --parallel
    cd ..
    
    if [ ! -f "$APP_PATH" ]; then
        echo -e "${RED}âŒ Build failed. Please check the build process.${NC}"
        exit 1
    fi
    
    echo -e "${GREEN}âœ… Application built successfully${NC}"
fi

# å‰µå»ºæ¼”ç¤ºé…ç½®
echo -e "${YELLOW}âš™ï¸  Creating demo configuration...${NC}"

# å‰µå»ºæ¼”ç¤ºç”¨çš„ç°¡åŒ–é…ç½®
mkdir -p Config
cat > Config/demo_servers.json << EOF
{
  "servers": [
    {
      "id": "demo_ollama",
      "name": "Demo Ollama Server",
      "host": "localhost",
      "port": 11434,
      "enabled": true,
      "max_connections": 3,
      "timeout_ms": 30000,
      "models": ["phi3:mini", "gemma:2b"],
      "load_balancer": {
        "strategy": "round_robin",
        "weight": 100
      }
    }
  ]
}
EOF

# å‰µå»ºæ¼”ç¤ºæ¨¡æ¿
cat > Config/demo_templates.json << EOF
{
  "templates": {
    "demo_skill": {
      "name": "Demo Skill Generation",
      "template": "Create a {academy} skill for level {level} character. Make it balanced and fun!",
      "preferred_models": ["phi3:mini"],
      "parameters": {
        "academy": {
          "type": "select", 
          "options": ["Warrior", "Mage", "Archer"],
          "default": "Warrior"
        },
        "level": {
          "type": "number",
          "min": 1,
          "max": 100,
          "default": 10
        }
      }
    }
  }
}
EOF

echo -e "${GREEN}âœ… Demo configuration created${NC}"

# å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
echo -e "${CYAN}================================================${NC}"
echo -e "${GREEN}ðŸŽ‰ Launching RANOnline LLM Integration Demo${NC}"
echo -e "${CYAN}================================================${NC}"

echo -e "${BLUE}ðŸŽ® Demo Features:${NC}"
echo -e "${BLUE}  â€¢ Multiple theme switching${NC}"
echo -e "${BLUE}  â€¢ Real-time AI request processing${NC}"
echo -e "${BLUE}  â€¢ Academy-based color theming${NC}"
echo -e "${BLUE}  â€¢ Progress monitoring${NC}"
echo -e "${BLUE}  â€¢ Batch request processing${NC}"
echo -e "${BLUE}  â€¢ Performance dashboard${NC}"

echo -e "${YELLOW}ðŸ’¡ Demo Tips:${NC}"
echo -e "${YELLOW}  1. Try different themes from the theme selector${NC}"
echo -e "${YELLOW}  2. Create requests with different academies${NC}"
echo -e "${YELLOW}  3. Test batch processing with multiple prompts${NC}"
echo -e "${YELLOW}  4. Monitor performance in the stats panel${NC}"
echo -e "${YELLOW}  5. Check the server management tab${NC}"

echo -e "${CYAN}================================================${NC}"

# è¨­å®šç’°å¢ƒè®Šæ•¸
export RANONLINE_DEMO_MODE=1
export RANONLINE_CONFIG_PATH="./Config"

# å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
"$APP_PATH" --demo --config-path="./Config"

# æ¸…ç†ï¼ˆå¦‚æžœéœ€è¦ï¼‰
cleanup() {
    echo -e "\n${YELLOW}ðŸ§¹ Cleaning up...${NC}"
    if [ ! -z "$OLLAMA_PID" ]; then
        echo -e "${BLUE}ðŸ›‘ Stopping Ollama service (PID: $OLLAMA_PID)${NC}"
        kill $OLLAMA_PID 2>/dev/null || true
    fi
    echo -e "${GREEN}âœ… Demo session ended${NC}"
}

trap cleanup EXIT
