# RANOnline AIæ±ºç­–æ ¸å¿ƒç³»çµ± v4.0.0

ğŸ§  **å¼·åŒ–AIæ±ºç­–ç³»çµ±** - é›†æˆå¤šç¨®å…ˆé€²AIæ±ºç­–ç®—æ³•çš„å®Œæ•´è§£æ±ºæ–¹æ¡ˆ

## ğŸ“‹ ç›®éŒ„
- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [ç³»çµ±æ¶æ§‹](#ç³»çµ±æ¶æ§‹)
- [å®‰è£èˆ‡é…ç½®](#å®‰è£èˆ‡é…ç½®)
- [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
- [è©³ç´°APIèªªæ˜](#è©³ç´°apièªªæ˜)
- [é…ç½®æ–‡ä»¶èªªæ˜](#é…ç½®æ–‡ä»¶èªªæ˜)
- [æ€§èƒ½å„ªåŒ–](#æ€§èƒ½å„ªåŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [é–‹ç™¼æŒ‡å—](#é–‹ç™¼æŒ‡å—)

---

## ğŸ¯ æ¦‚è¿°

RANOnline AIæ±ºç­–æ ¸å¿ƒç³»çµ±æ˜¯ä¸€å€‹å…ˆé€²çš„AIæ±ºç­–æ¡†æ¶ï¼Œå°ˆç‚ºMMOéŠæˆ²ä¸­çš„æ™ºèƒ½NPCå’ŒAIç©å®¶è¨­è¨ˆã€‚ç³»çµ±é›†æˆäº†å¤šç¨®AIæ±ºç­–ç®—æ³•ï¼ŒåŒ…æ‹¬æ•ˆç”¨å‡½æ•¸ç³»çµ±ã€è¡Œç‚ºæ¨¹ã€å¼·åŒ–å­¸ç¿’(Q-Learning)ã€åˆ†å±¤æ±ºç­–ç­‰ï¼Œæä¾›å¯çµ„åˆã€å¯æ“´å±•çš„AIæ±ºç­–è§£æ±ºæ–¹æ¡ˆã€‚

### ğŸŒŸ ä¸»è¦å„ªå‹¢

- **ğŸ”„ å¤šç­–ç•¥æ”¯æ´**: æ”¯æ´6ç¨®ä¸åŒçš„æ±ºç­–ç­–ç•¥ï¼Œå¯å‹•æ…‹åˆ‡æ›
- **ğŸ“š å­¸ç¿’èƒ½åŠ›**: é›†æˆQ-Learningå¼·åŒ–å­¸ç¿’ï¼ŒAIå¯è‡ªä¸»å­¸ç¿’å’Œé€²åŒ–
- **ğŸ”¥ ç†±æ›´æ–°**: æ”¯æ´é…ç½®æ–‡ä»¶ç†±æ›´æ–°ï¼Œç„¡éœ€é‡å•Ÿå³å¯èª¿æ•´AIè¡Œç‚º
- **âš¡ é«˜æ€§èƒ½**: å„ªåŒ–çš„æ±ºç­–ç®—æ³•ï¼Œæ”¯æ´å¤§é‡AIå¯¦é«”åŒæ™‚é‹è¡Œ
- **ğŸ§© æ¨¡çµ„åŒ–**: å®Œå…¨æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œæ˜“æ–¼æ“´å±•å’Œè‡ªå®šç¾©
- **ğŸ“Š ç›£æ§å·¥å…·**: å…§å»ºæ€§èƒ½ç›£æ§å’Œèª¿è©¦å·¥å…·

---

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### ğŸ›ï¸ å…­å¤§æ±ºç­–ç­–ç•¥

1. **æ•ˆç”¨å‡½æ•¸ç³»çµ± (Utility-Based)**
   - å¤šç¶­åº¦æ•ˆç”¨è¨ˆç®— (æˆ°é¬¥ã€ç”Ÿå­˜ã€æ”¯æ´)
   - å‹•æ…‹æ¬Šé‡èª¿æ•´
   - æ”¯æ´è‡ªå®šç¾©æ•ˆç”¨å‡½æ•¸

2. **è¡Œç‚ºæ¨¹æ±ºç­– (Behavior Tree)**
   - å®Œæ•´çš„ç¯€é»ç³»çµ± (æ¢ä»¶ã€å‹•ä½œã€çµ„åˆå™¨)
   - JSONé…ç½®æ”¯æ´
   - å¯è¦–åŒ–èª¿è©¦

3. **å¼·åŒ–å­¸ç¿’ (Q-Learning)**
   - æ·±åº¦Qç¶²è·¯æ”¯æ´
   - ç¶“é©—å›æ”¾æ©Ÿåˆ¶
   - è‡ªé©æ‡‰æ¢ç´¢ç­–ç•¥

4. **åˆ†å±¤æ±ºç­– (Hierarchical)**
   - ä¸‰å±¤æ±ºç­–æ¶æ§‹ (æˆ°ç•¥â†’æˆ°è¡“â†’æ“ä½œ)
   - å‹•æ…‹ç›®æ¨™ç®¡ç†
   - è¨ˆåŠƒé‡æ–°è¦åŠƒ

5. **æ··åˆç­–ç•¥ (Hybrid)**
   - å¤šç­–ç•¥çµ„åˆæ±ºç­–
   - æŠ•ç¥¨æ©Ÿåˆ¶
   - ä¿¡å¿ƒåº¦åŠ æ¬Š

6. **è‡ªå®šç¾©ç­–ç•¥ (Custom)**
   - é–‹æ”¾å¼ä»‹é¢
   - æ’ä»¶å¼æ¶æ§‹
   - å®Œå…¨è‡ªå®šç¾©é‚è¼¯

### ğŸ”§ æ ¸å¿ƒçµ„ä»¶

```
JyAI å‘½åç©ºé–“
â”œâ”€â”€ AIDecisionCore        # æ±ºç­–æ ¸å¿ƒå¼•æ“
â”œâ”€â”€ AIPlayerBrain         # AIç©å®¶å¤§è…¦
â”œâ”€â”€ AIPlayerManager       # AIç©å®¶ç®¡ç†å™¨
â”œâ”€â”€ UtilitySystem         # æ•ˆç”¨å‡½æ•¸ç³»çµ±
â”œâ”€â”€ BehaviorTree          # è¡Œç‚ºæ¨¹ç³»çµ±
â”œâ”€â”€ QLearningAgent        # Qå­¸ç¿’ä»£ç†
â”œâ”€â”€ HierarchicalPlanner   # åˆ†å±¤è¦åŠƒå™¨
â”œâ”€â”€ EnvironmentPerceptor  # ç’°å¢ƒæ„ŸçŸ¥å™¨
â””â”€â”€ ConfigManager         # é…ç½®ç®¡ç†å™¨
```

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ‡‰ç”¨å±¤ (Application)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         AIç©å®¶ç®¡ç†å™¨                  â”‚
â”‚      (AIPlayerManager)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         AIç©å®¶å¤§è…¦                   â”‚
â”‚       (AIPlayerBrain)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         AIæ±ºç­–æ ¸å¿ƒ                   â”‚
â”‚      (AIDecisionCore)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ±ºç­–ç­–ç•¥å±¤ (Strategy Layer)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Utility â”‚Behavior â”‚Q-Learningâ”‚    â”‚
â”‚  â”‚ System  â”‚  Tree   â”‚ Agent   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ”¯æ´ç³»çµ±å±¤ (Support Layer)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Config  â”‚ Percep- â”‚ Learn-  â”‚    â”‚
â”‚  â”‚Manager  â”‚  tor    â”‚ ing     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ å®‰è£èˆ‡é…ç½®

### ç³»çµ±è¦æ±‚

- **ç·¨è­¯å™¨**: C++17 æˆ–æ›´æ–°ç‰ˆæœ¬
- **Qt Framework**: Qt 5.15+ æˆ– Qt 6.x
- **è¨˜æ†¶é«”**: å»ºè­° 4GB+ (å–æ±ºæ–¼AIå¯¦é«”æ•¸é‡)
- **CPU**: æ”¯æ´å¤šæ ¸å¿ƒè™•ç†å™¨

### ç·¨è­¯æ­¥é©Ÿ

1. **æª¢æŸ¥ä¾è³´é …**
```bash
# ç¢ºä¿å·²å®‰è£ Qt é–‹ç™¼ç’°å¢ƒ
qmake --version
```

2. **æ·»åŠ åˆ°é …ç›®**
```cpp
// åœ¨ CMakeLists.txt æˆ– .pro æ–‡ä»¶ä¸­æ·»åŠ 
SOURCES += \
    AIDecisionCore.cpp \
    AIPlayerBrain.cpp \
    AIBehaviorSystems.cpp \
    AIDecisionCoreTest.cpp

HEADERS += \
    AIDecisionCore.h \
    AIPlayerBrain.h
```

3. **åŒ…å«é ­æ–‡ä»¶**
```cpp
#include "AIDecisionCore.h"
#include "AIPlayerBrain.h"
using namespace JyAI;
```

### é…ç½®æ–‡ä»¶è¨­ç½®

å°‡é…ç½®æ–‡ä»¶è¤‡è£½åˆ°é …ç›®ç›®éŒ„ï¼š
- `ai_decision_config.json` - ä¸»é…ç½®æ–‡ä»¶
- `behavior_tree_config.json` - è¡Œç‚ºæ¨¹é…ç½®
- `qlearning_config.json` - Qå­¸ç¿’é…ç½®

---

## âš¡ å¿«é€Ÿé–‹å§‹

### åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹

```cpp
#include "AIPlayerBrain.h"
#include <QtCore/QCoreApplication>

int main(int argc, char *argv[])
{
    QCoreApplication app(argc, argv);
    
    // 1. å‰µå»ºAIç©å®¶å¤§è…¦
    auto brain = std::make_unique<JyAI::AIPlayerBrain>("player_001");
    
    // 2. è¨­ç½®ç©å®¶æ•¸æ“š
    RANOnline::AI::AIPlayerData playerData;
    playerData.id = "player_001";
    playerData.currentHP = 100;
    playerData.maxHP = 100;
    playerData.level = 25;
    brain->setPlayerData(playerData);
    
    // 3. é¸æ“‡æ±ºç­–ç­–ç•¥
    brain->setDecisionStrategy(JyAI::DecisionStrategyType::HYBRID);
    
    // 4. å•Ÿå‹•AI
    brain->start();
    
    // 5. é€£æ¥ä¿¡è™Ÿä»¥æ¥æ”¶AIè¡Œç‚º
    QObject::connect(brain.get(), &JyAI::AIPlayerBrain::moveRequested,
                     [](const QString &playerId, const QVector3D &position) {
        qDebug() << "Player" << playerId << "wants to move to" << position;
    });
    
    return app.exec();
}
```

### ç®¡ç†å¤šå€‹AIç©å®¶

```cpp
#include "AIPlayerBrain.h"

void setupMultipleAIPlayers()
{
    // å‰µå»ºAIç©å®¶ç®¡ç†å™¨
    JyAI::AIPlayerManager manager;
    
    // æ·»åŠ å¤šå€‹AIç©å®¶
    for (int i = 1; i <= 10; ++i) {
        QString playerId = QString("ai_player_%1").arg(i);
        
        RANOnline::AI::AIPlayerData playerData;
        playerData.id = playerId;
        playerData.currentHP = 100;
        playerData.maxHP = 100;
        playerData.level = 20 + (i % 20);
        
        manager.addPlayer(playerId, playerData);
    }
    
    // è¨­ç½®æ‰€æœ‰AIä½¿ç”¨æ··åˆç­–ç•¥
    manager.setAllPlayersStrategy(JyAI::DecisionStrategyType::HYBRID);
    
    // å•Ÿå‹•æ‰€æœ‰AI
    manager.start();
    
    // ç²å–ç®¡ç†å™¨çµ±è¨ˆ
    auto stats = manager.getManagerStats();
    qDebug() << "Managing" << stats.totalPlayers << "AI players";
}
```

---

## ğŸ“š è©³ç´°APIèªªæ˜

### AIDecisionCore é¡

æ ¸å¿ƒæ±ºç­–å¼•æ“ï¼Œè² è²¬åŸ·è¡ŒAIæ±ºç­–é‚è¼¯ã€‚

#### ä¸»è¦æ–¹æ³•

```cpp
class AIDecisionCore {
public:
    // æ§‹é€ å’Œææ§‹
    AIDecisionCore();
    ~AIDecisionCore();
    
    // æ±ºç­–æ–¹æ³•
    AIAction makeDecision(const PerceptionData &perception);
    void setStrategy(DecisionStrategyType strategy);
    DecisionStrategyType getCurrentStrategy() const;
    
    // å­¸ç¿’æ–¹æ³•
    void learn(const PerceptionData &perception, 
               const AIAction &action, 
               float reward);
    
    // é…ç½®ç®¡ç†
    bool loadConfiguration(const QString &configPath);
    bool reloadConfiguration();
    
    // æ¨¡å‹ç®¡ç†
    bool saveModel(const QString &modelPath);
    bool loadModel(const QString &modelPath);
    
    // çµ±è¨ˆå’Œèª¿è©¦
    AIStatistics getStatistics() const;
    void enableDebug(bool enabled);
};
```

#### æ±ºç­–ç­–ç•¥é¡å‹

```cpp
enum class DecisionStrategyType {
    UTILITY_BASED,  // æ•ˆç”¨å‡½æ•¸æ±ºç­–
    BEHAVIOR_TREE,  // è¡Œç‚ºæ¨¹æ±ºç­–
    Q_LEARNING,     // Qå­¸ç¿’æ±ºç­–
    HIERARCHICAL,   // åˆ†å±¤æ±ºç­–
    HYBRID,         // æ··åˆç­–ç•¥
    CUSTOM          // è‡ªå®šç¾©ç­–ç•¥
};
```

### AIPlayerBrain é¡

AIç©å®¶å¤§è…¦ï¼Œé›†æˆAIDecisionCoreä¸¦æä¾›å®Œæ•´çš„AIç©å®¶å¯¦ç¾ã€‚

#### ä¸»è¦åŠŸèƒ½

```cpp
class AIPlayerBrain : public QObject {
    Q_OBJECT
    
public:
    // æ§‹é€ å’Œæ§åˆ¶
    explicit AIPlayerBrain(const QString &playerId, QObject *parent = nullptr);
    
    void start();       // å•Ÿå‹•AI
    void stop();        // åœæ­¢AI
    void pause();       // æš«åœAI
    void resume();      // æ¢å¾©AI
    
    // é…ç½®æ–¹æ³•
    void setPlayerData(const RANOnline::AI::AIPlayerData &playerData);
    void setDecisionStrategy(DecisionStrategyType strategy);
    void setUpdateFrequency(int milliseconds);
    void enableDebug(bool enabled);
    
    // ç›£æ§æ–¹æ³•
    QString getDebugInfo() const;
    PerformanceStats getPerformanceStats() const;
    QList<ActionRecord> getActionHistory(int limit = 50) const;

signals:
    // éŠæˆ²å‹•ä½œä¿¡è™Ÿ
    void moveRequested(const QString &playerId, const QVector3D &position);
    void attackRequested(const QString &playerId, const QString &targetId);
    void skillUseRequested(const QString &playerId, const QString &skillId, const QString &targetId);
    void itemUseRequested(const QString &playerId, const QString &itemId);
    void interactionRequested(const QString &playerId, const QString &objectId);
    
    // AIç‹€æ…‹ä¿¡è™Ÿ
    void actionExecuted(const QString &playerId, const AIAction &action);
    void errorOccurred(const QString &playerId, const QString &error);
    void teamSupportNeeded(const QString &playerId, const QString &allyId);
};
```

### AIPlayerManager é¡

AIç©å®¶ç®¡ç†å™¨ï¼Œè² è²¬ç®¡ç†å¤šå€‹AIç©å®¶å¯¦ä¾‹ã€‚

```cpp
class AIPlayerManager : public QObject {
    Q_OBJECT
    
public:
    // ç©å®¶ç®¡ç†
    bool addPlayer(const QString &playerId, const RANOnline::AI::AIPlayerData &playerData);
    bool removePlayer(const QString &playerId);
    AIPlayerBrain* getPlayer(const QString &playerId);
    QStringList getPlayerIds() const;
    void clearAllPlayers();
    
    // æ‰¹é‡æ§åˆ¶
    void startAllPlayers();
    void stopAllPlayers();
    void setAllPlayersStrategy(DecisionStrategyType strategy);
    void setAllPlayersUpdateFrequency(int milliseconds);
    
    // ç®¡ç†å™¨æ§åˆ¶
    void start();
    void stop();
    void setMaxPlayers(int maxPlayers);
    
    // çµ±è¨ˆç›£æ§
    ManagerStats getManagerStats() const;
    QString getDetailedStats() const;
};
```

---

## âš™ï¸ é…ç½®æ–‡ä»¶èªªæ˜

### ä¸»é…ç½®æ–‡ä»¶ (ai_decision_config.json)

```json
{
  "aiDecisionConfig": {
    "globalSettings": {
      "enableDebugMode": false,
      "enableLearning": true,
      "maxDecisionHistorySize": 1000,
      "logLevel": "INFO"
    },
    
    "strategySettings": {
      "defaultStrategy": "HYBRID",
      "allowStrategyChange": true,
      "adaptiveStrategySelection": true
    },
    
    "utilitySystem": {
      "combatWeight": 0.4,
      "survivalWeight": 0.4,
      "supportWeight": 0.2,
      "utilityThreshold": 0.5
    }
  }
}
```

### è¡Œç‚ºæ¨¹é…ç½® (behavior_tree_config.json)

å®šç¾©AIçš„è¡Œç‚ºé‚è¼¯æ¨¹ï¼ŒåŒ…å«æ¢ä»¶ç¯€é»ã€å‹•ä½œç¯€é»å’Œçµ„åˆå™¨ç¯€é»ã€‚

```json
{
  "behaviorTrees": {
    "combatTree": {
      "rootNode": "CombatRootSelector",
      "nodes": {
        "CombatRootSelector": {
          "type": "Selector",
          "children": ["EmergencyFleeSequence", "AggressiveCombatSequence"]
        },
        "EmergencyFleeSequence": {
          "type": "Sequence",
          "children": ["CheckCriticalHealth", "ExecuteFlee"]
        }
      }
    }
  }
}
```

### Qå­¸ç¿’é…ç½® (qlearning_config.json)

é…ç½®å¼·åŒ–å­¸ç¿’åƒæ•¸ï¼ŒåŒ…æ‹¬ç¶²è·¯æ¶æ§‹ã€å­¸ç¿’ç‡ã€æ¢ç´¢ç­–ç•¥ç­‰ã€‚

```json
{
  "qLearningConfig": {
    "algorithmSettings": {
      "learningRate": 0.1,
      "discountFactor": 0.95,
      "explorationRate": 0.1
    },
    "networkArchitecture": {
      "hiddenLayers": [256, 128, 64],
      "activationFunction": "relu"
    }
  }
}
```

---

## ğŸ¯ å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹

### ç¯„ä¾‹1: æˆ°é¬¥AI

```cpp
void setupCombatAI()
{
    auto combatBrain = std::make_unique<JyAI::AIPlayerBrain>("combat_ai");
    
    // è¨­ç½®æ”»æ“Šå‹AIé…ç½®
    combatBrain->setDecisionStrategy(JyAI::DecisionStrategyType::UTILITY_BASED);
    
    // é€£æ¥æˆ°é¬¥è¡Œç‚º
    QObject::connect(combatBrain.get(), &JyAI::AIPlayerBrain::attackRequested,
                     [](const QString &playerId, const QString &targetId) {
        // åŸ·è¡Œæ”»æ“Šé‚è¼¯
        executeCombatAttack(playerId, targetId);
    });
    
    QObject::connect(combatBrain.get(), &JyAI::AIPlayerBrain::skillUseRequested,
                     [](const QString &playerId, const QString &skillId, const QString &targetId) {
        // åŸ·è¡ŒæŠ€èƒ½é‚è¼¯
        executeSkillAttack(playerId, skillId, targetId);
    });
    
    combatBrain->start();
}
```

### ç¯„ä¾‹2: æ”¯æ´AI

```cpp
void setupSupportAI()
{
    auto supportBrain = std::make_unique<JyAI::AIPlayerBrain>("support_ai");
    
    // è¨­ç½®æ”¯æ´å‹AIé…ç½®
    supportBrain->setDecisionStrategy(JyAI::DecisionStrategyType::HIERARCHICAL);
    
    // é€£æ¥æ”¯æ´è¡Œç‚º
    QObject::connect(supportBrain.get(), &JyAI::AIPlayerBrain::teamSupportNeeded,
                     [](const QString &playerId, const QString &allyId) {
        // åŸ·è¡Œæ”¯æ´é‚è¼¯
        provideSupportToAlly(playerId, allyId);
    });
    
    supportBrain->start();
}
```

### ç¯„ä¾‹3: å­¸ç¿’å‹AI

```cpp
void setupLearningAI()
{
    auto learningBrain = std::make_unique<JyAI::AIPlayerBrain>("learning_ai");
    
    // è¨­ç½®å­¸ç¿’å‹AIé…ç½®
    learningBrain->setDecisionStrategy(JyAI::DecisionStrategyType::Q_LEARNING);
    
    // ç›£æ§å­¸ç¿’é€²åº¦
    QObject::connect(learningBrain.get(), &JyAI::AIPlayerBrain::actionExecuted,
                     [learningBrain = learningBrain.get()](const QString &playerId, const JyAI::AIAction &action) {
        // è¨˜éŒ„è¡Œç‚ºæ•ˆæœä¸¦æä¾›å›é¥‹
        float reward = calculateActionReward(action);
        // learningBrain->provideFeedback(reward); // å¦‚æœæœ‰æ­¤æ–¹æ³•
    });
    
    learningBrain->start();
}
```

---

## ğŸ“Š æ€§èƒ½å„ªåŒ–

### å„ªåŒ–å»ºè­°

1. **æ›´æ–°é »ç‡èª¿æ•´**
```cpp
// æ ¹æ“šAIé‡è¦æ€§èª¿æ•´æ›´æ–°é »ç‡
brain->setUpdateFrequency(100);  // é‡è¦AI: 100ms
brain->setUpdateFrequency(200);  // ä¸€èˆ¬AI: 200ms
brain->setUpdateFrequency(500);  // èƒŒæ™¯AI: 500ms
```

2. **æ„ŸçŸ¥ç¯„åœé™åˆ¶**
```cpp
// åœ¨é…ç½®ä¸­é™åˆ¶æ„ŸçŸ¥ç¯„åœä»¥æå‡æ€§èƒ½
"environmentPerception": {
  "perceptionRadius": 30.0,      // æ¸›å°‘æ„ŸçŸ¥åŠå¾‘
  "updateFrequency": 100,        // å¢åŠ æ›´æ–°é–“éš”
  "enablePrediction": false      // é—œé–‰é æ¸¬åŠŸèƒ½
}
```

3. **è¨˜æ†¶é«”ç®¡ç†**
```cpp
// é™åˆ¶æ­·å²è¨˜éŒ„å¤§å°
"globalSettings": {
  "maxDecisionHistorySize": 500,  // æ¸›å°‘æ­·å²è¨˜éŒ„
  "enableGarbageCollection": true
}
```

### æ€§èƒ½ç›£æ§

```cpp
// ç²å–æ€§èƒ½çµ±è¨ˆ
auto stats = brain->getPerformanceStats();
qDebug() << "Average decision time:" << stats.averageDecisionTime << "ms";
qDebug() << "Total updates:" << stats.totalUpdates;

// ç®¡ç†å™¨çµ±è¨ˆ
auto managerStats = manager.getManagerStats();
qDebug() << "Active players:" << managerStats.activePlayers;
qDebug() << "Average decision time:" << managerStats.averageDecisionTime << "ms";
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **AIæ±ºç­–é€Ÿåº¦ç·©æ…¢**
   - æª¢æŸ¥æ›´æ–°é »ç‡è¨­ç½®
   - æ¸›å°‘æ„ŸçŸ¥ç¯„åœ
   - é—œé–‰ä¸å¿…è¦çš„èª¿è©¦åŠŸèƒ½

2. **AIè¡Œç‚ºä¸åˆç†**
   - æª¢æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¢ºè¼‰å…¥
   - é©—è­‰æ„ŸçŸ¥æ•¸æ“šæ˜¯å¦æº–ç¢º
   - èª¿æ•´æ•ˆç”¨å‡½æ•¸æ¬Šé‡

3. **è¨˜æ†¶é«”ä½¿ç”¨éé«˜**
   - é™åˆ¶æ±ºç­–æ­·å²å¤§å°
   - æ¸›å°‘AIå¯¦é«”æ•¸é‡
   - å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–é¸é …

4. **å­¸ç¿’æ•ˆæœä¸ä½³**
   - èª¿æ•´å­¸ç¿’ç‡å’Œæ¢ç´¢ç‡
   - æª¢æŸ¥çå‹µå‡½æ•¸è¨­è¨ˆ
   - å¢åŠ è¨“ç·´æ•¸æ“šé‡

### èª¿è©¦æŠ€å·§

```cpp
// å•Ÿç”¨èª¿è©¦æ¨¡å¼
brain->enableDebug(true);

// ç²å–èª¿è©¦è³‡è¨Š
QString debugInfo = brain->getDebugInfo();
qDebug() << debugInfo;

// æŸ¥çœ‹è¡Œç‚ºæ­·å²
auto history = brain->getActionHistory(20);
for (const auto &record : history) {
    qDebug() << "Action:" << static_cast<int>(record.action.type)
             << "Time:" << record.timestamp.toString();
}
```

---

## ğŸ‘¨â€ğŸ’» é–‹ç™¼æŒ‡å—

### æ“´å±•è‡ªå®šç¾©ç­–ç•¥

```cpp
// 1. å¯¦ç¾è‡ªå®šç¾©æ±ºç­–ç­–ç•¥
class CustomStrategy : public IDecisionStrategy {
public:
    AIAction makeDecision(const PerceptionData &perception) override {
        AIAction action;
        // å¯¦ç¾è‡ªå®šç¾©æ±ºç­–é‚è¼¯
        action.type = ActionType::MOVE;
        action.confidence = 0.8f;
        action.isValid = true;
        return action;
    }
    
    void learn(const PerceptionData &perception, 
               const AIAction &action, 
               float reward) override {
        // å¯¦ç¾å­¸ç¿’é‚è¼¯
    }
};

// 2. è¨»å†Šè‡ªå®šç¾©ç­–ç•¥
auto customStrategy = std::make_unique<CustomStrategy>();
decisionCore->setCustomStrategy(std::move(customStrategy));
decisionCore->setStrategy(DecisionStrategyType::CUSTOM);
```

### æ·»åŠ è‡ªå®šç¾©è¡Œç‚º

```cpp
// æ“´å±•å‹•ä½œé¡å‹
enum class CustomActionType {
    CAST_SPELL = 100,
    TRADE_ITEM = 101,
    BUILD_STRUCTURE = 102
};

// åœ¨AIPlayerBrainä¸­è™•ç†è‡ªå®šç¾©å‹•ä½œ
void AIPlayerBrain::executeCustomAction(const AIAction &action) {
    switch (static_cast<CustomActionType>(action.type)) {
        case CustomActionType::CAST_SPELL:
            executeMagicSpell(action);
            break;
        case CustomActionType::TRADE_ITEM:
            executeTrading(action);
            break;
        default:
            break;
    }
}
```

### é›†æˆç¾æœ‰ç³»çµ±

```cpp
// èˆ‡RANOnlineç¾æœ‰AIç³»çµ±é›†æˆ
class RANOnlineAIBridge {
public:
    void integrateWithExistingAI(AIPlayerBrain *brain) {
        // é€£æ¥åˆ°ç¾æœ‰çš„AIç³»çµ±
        connect(brain, &AIPlayerBrain::moveRequested,
                this, &RANOnlineAIBridge::handleMoveRequest);
        
        connect(brain, &AIPlayerBrain::attackRequested,
                this, &RANOnlineAIBridge::handleAttackRequest);
    }
    
private:
    void handleMoveRequest(const QString &playerId, const QVector3D &position) {
        // è½‰ç™¼åˆ°RANOnlineçš„ç§»å‹•ç³»çµ±
        RANOnline::AI::movePlayer(playerId, position);
    }
    
    void handleAttackRequest(const QString &playerId, const QString &targetId) {
        // è½‰ç™¼åˆ°RANOnlineçš„æˆ°é¬¥ç³»çµ±
        RANOnline::AI::attackTarget(playerId, targetId);
    }
};
```

---

## ğŸ“ˆ ç‰ˆæœ¬æ­·å²

### v4.0.0 (ç•¶å‰ç‰ˆæœ¬)
- âœ… å®Œæ•´çš„AIæ±ºç­–æ ¸å¿ƒç³»çµ±
- âœ… å…­ç¨®æ±ºç­–ç­–ç•¥å¯¦ç¾
- âœ… AIç©å®¶å¤§è…¦å’Œç®¡ç†å™¨
- âœ… é…ç½®æ–‡ä»¶ç†±æ›´æ–°
- âœ… æ€§èƒ½ç›£æ§å’Œèª¿è©¦å·¥å…·

### å³å°‡æ¨å‡ºçš„åŠŸèƒ½
- ğŸ”„ æ·±åº¦å¼·åŒ–å­¸ç¿’æ”¯æ´
- ğŸ”„ å¤šæ™ºèƒ½é«”å”ä½œç®—æ³•
- ğŸ”„ å¯è¦–åŒ–èª¿è©¦ç•Œé¢
- ğŸ”„ é›²ç«¯å­¸ç¿’æœå‹™é›†æˆ

---

## ğŸ“ æŠ€è¡“æ”¯æ´

å¦‚éœ€æŠ€è¡“æ”¯æ´æˆ–æœ‰ä»»ä½•å•é¡Œï¼Œè«‹è¯ç¹«ï¼š

- **Email**: ai-support@ranonline.com
- **æ–‡æª”**: https://docs.ranonline.com/ai-decision-core
- **GitHub**: https://github.com/ranonline/ai-decision-core

---

## ğŸ“„ è¨±å¯è­‰

Copyright Â© 2025 JyæŠ€è¡“åœ˜éšŠ. All rights reserved.

æœ¬è»Ÿä»¶æŒ‰ç…§ MIT è¨±å¯è­‰åˆ†ç™¼ã€‚è©³ç´°ä¿¡æ¯è«‹åƒé–± LICENSE æ–‡ä»¶ã€‚

---

**ğŸ¯ RANOnline AIæ±ºç­–æ ¸å¿ƒç³»çµ± - è®“æ‚¨çš„éŠæˆ²AIæ›´æ™ºèƒ½ã€æ›´çœŸå¯¦ï¼**
